ğŸ§  Analyse de Sentiments â€” Deep Learning

Ce projet explore plusieurs approches de classification de sentiments sur le jeu de donnÃ©es Sentiment140 (Twitter).
Lâ€™objectif est de comparer des modÃ¨les traditionnels (TF-IDF + RÃ©gression Logistique) et des modÃ¨les neuronaux modernes (TextCNN, LSTM, BERT fine-tunÃ©).

ğŸ“ Structure du projet

Realisez_une_analyse_de_sentiments_deep_learning_potelet_laurent/
â”‚
â”œâ”€â”€ data/                    # Dossier local des donnÃ©es (non versionnÃ©)
â”œâ”€â”€ models/                  # ModÃ¨les sauvegardÃ©s (non versionnÃ©)
â”œâ”€â”€ mlruns/                  # Suivi des expÃ©riences MLflow (non versionnÃ©)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_tfidf_lr.py      # Baseline TF-IDF + LogisticRegression
â”‚   â”œâ”€â”€ run_textcnn.py       # CNN 1D sur embeddings
â”‚   â”œâ”€â”€ run_lstm_torch.py    # LSTM bidirectionnel PyTorch
â”‚   â”œâ”€â”€ run_bert.py          # Fine-tuning DistilBERT
â”‚   â””â”€â”€ maintenance/
â”‚       â””â”€â”€ nettoyage_mlflow.py  # Script de nettoyage MLflow
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

âš™ï¸ Installation

1ï¸âƒ£ CrÃ©er et activer un environnement virtuel
python -m venv .venv_p7
source .venv_p7/bin/activate      # macOS / Linux
# ou sur Windows :
# .venv_p7\Scripts\activate

2ï¸âƒ£ Installer les dÃ©pendances
pip install -r requirements.txt

3ï¸âƒ£ (Optionnel) VÃ©rifier PyTorch et accÃ©lÃ©ration
python - <<'PY'
import torch
print("Torch:", torch.__version__, "| MPS dispo:", torch.backends.mps.is_available())
PY

ğŸ§¾ DonnÃ©es

Le dataset Sentiment140 contient 1,6 million de tweets annotÃ©s :
	â€¢	0 â†’ nÃ©gatif
	â€¢	4 â†’ positif

TÃ©lÃ©chargement manuel :
https://www.kaggle.com/datasets/kazanova/sentiment140

Place le fichier dans ./data/training.1600000.processed.noemoticon.csv

ğŸš€ Lancement des modÃ¨les

Baseline TF-IDF + Logistic Regression
python -m scripts.run_tfidf_lr \
  --data "./data/training.1600000.processed.noemoticon.csv" \
  --subset_rows 10000 \
  --exp_name "baseline_tfidf_lr"

TextCNN (PyTorch)
python -m scripts.run_textcnn \
  --data "./data/training.1600000.processed.noemoticon.csv" \
  --subset_rows 50000 \
  --epochs 5 --batch_size 64 \
  --exp_name "textcnn_full_ft"

LSTM bidirectionnel
python -m scripts.run_lstm_torch \
  --data "./data/training.1600000.processed.noemoticon.csv" \
  --subset_rows 50000 \
  --epochs 5 --batch_size 64 \
  --exp_name "lstm_full"

BERT (DistilBERT fine-tuned)
TRANSFORMERS_NO_TF=1 TOKENIZERS_PARALLELISM=false \
python -m scripts.run_bert \
  --data "./data/training.1600000.processed.noemoticon.csv" \
  --subset_rows 100000 \
  --model_name "distilbert-base-uncased" \
  --epochs 3 --batch_size 48 --max_length 128 --lr 3e-5 \
  --early_stop_patience 1 \
  --exp_name "bert_finetune_distilbert"

ğŸ“Š Suivi avec MLflow
mlflow ui --backend-store-uri file:./mlruns --port 5000

Puis ouvrir :
http://127.0.0.1:5000


ğŸ§® MÃ©triques suivies

Nom dans MLflow         Description
train_loss              Moyenne des pertes sur lâ€™entraÃ®nement
val_loss                Moyenne des pertes sur la validation
train_f1, val_f1        F1-macro score (moyenne Ã©quilibrÃ©e)
train_acc, val_acc      PrÃ©cision globale
duration                Temps total dâ€™exÃ©cution
best_val_f1             Meilleur F1 atteint (checkpoint sauvegardÃ©)

ğŸ§¹ Maintenance
tar -czf backup_mlruns_$(date +%F_%H%M).tar.gz mlruns

Nettoyer les vieilles runs # Si besoin
python -m scripts.maintenance.nettoyage_mlflow \
  --experiment "textcnn_full_ft" \                  # Renseigner le nom de l'expÃ©rimentation Ã  nettoyer
  --metric val_f1_macro --top_k 3                   # Changer le nom de la mÃ©trique d'Ã©valuation



ğŸ“ˆ RÃ©sumÃ© des performances (approximatives)

ModÃ¨le                  F1_macro (Val)       DurÃ©e (â‰ˆ)
TF-IDF + LogReg         0.78                 1 min
TextCNN                 0.83â€“0.84            5â€“10 min
LSTM bidirectionnel     0.79â€“0.80            10â€“15 min
DistilBERT fine-tuned   0.84â€“0.85            ~1 h


ğŸ§© AmÃ©liorations possibles
	â€¢	Optimisation des hyperparamÃ¨tres
	â€¢	Test de modÃ¨les roberta-base, bertweet-base
	â€¢	Visualisation des embeddings
	â€¢	Sauvegarde automatique des meilleurs checkpoints


ğŸ‘¤ Auteur

Laurent Potelet